{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This code was adapted from [Alexander Held's \"Example of a differentiable analysis\" repository](https://github.com/alexander-held/differentiable-analysis-example/)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import grad, vmap, jit\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"font.size\": 14,\n",
    "        \"figure.figsize\": (7, 5),\n",
    "        \"figure.facecolor\": (1, 1, 1, 1),\n",
    "        \"figure.dpi\": 100,\n",
    "        #         \"figure.dpi\": 300,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "We have two processes:\n",
    "\n",
    "- signal `S`,\n",
    "- background `B`,\n",
    "\n",
    "and we observe events generated from these processes.\n",
    "The observation consist of measuring a single observable.\n",
    "We have Monte Carlo predictions in the form of events generated for both processes, which tell us how many events we observe as a function of the observable $x$.\n",
    "\n",
    "We want to do a single-bin counting experiment to establish the presence of the signal process.\n",
    "The significance calculation for this is found below.\n",
    "To maximize the significance, this toy analysis introduces a cut.\n",
    "We only let events with an observable $x>c$ enter our bin, where $c$ is a cut value we intend to optimize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation and visualization\n",
    "The background and signal events in this toy case have slightly different values of the observable $x$ on average, but the spread of the background along the observable is quite large. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nBg = 8000\n",
    "nSig = 300\n",
    "background = np.random.normal(40, 10, nBg)\n",
    "signal = np.random.normal(50, 5, nSig)\n",
    "\n",
    "bins = jnp.linspace(0, 80, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "alpha = 1.0\n",
    "ax.hist(background, bins=bins, alpha=alpha, label=[\"Background\"])\n",
    "ax.hist(signal, bins=bins, alpha=alpha, label=[\"Signal\"])\n",
    "ax.set_xlabel(r\"Observable $x$\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.legend(loc=\"best\")\n",
    "fig.savefig(\"plots/signal_background_shapes.png\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist([background, signal], bins=bins, stacked=True, label=[\"Background\", \"Signal\"])\n",
    "ax.set_xlabel(r\"Observable $x$\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.legend(loc=\"best\")\n",
    "fig.savefig(\"plots/signal_background_stacked.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate significance for given cut and scan\n",
    "This significance is given by the amount of signal and background events in the bin as \n",
    "$\\sqrt{2(S+B) \\log(1+\\frac{S}{B}) -2S}$.\n",
    "Expand $\\log(1+y) \\approx y-\\frac{y^2}{2}$ to recover $\\frac{S}{\\sqrt{B}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def significance(S, B):\n",
    "    \"\"\"calculate the significance according to the formula above\"\"\"\n",
    "    return jnp.sqrt(2 * ((S + B) * jnp.log(1 + S / B) - S))\n",
    "\n",
    "\n",
    "def get_significance(cut, S, B):\n",
    "    \"\"\"calculate the significance at a given cut value for signal and background events\"\"\"\n",
    "    S_cut = len(S[S > cut])\n",
    "    B_cut = len(B[B > cut])\n",
    "    return significance(S_cut, B_cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate as a baseline the significance for when the cut is $c=0$, so we let all events $x>0$ pass the cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_significance = get_significance(0, signal, background)\n",
    "print(\"the baseline significance is\", baseline_significance, \"Ïƒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example it is straightforward to just scan for the optimal setting, let's do that before we use any autodiff. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts = jnp.linspace(20, 70, 500)\n",
    "significances = [get_significance(cut, signal, background) for cut in cuts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(cuts, significances, c=\"C2\")\n",
    "ax.set_xlabel(r\"Cut position on $x$\")\n",
    "ax.set_ylabel(\"Significance\")\n",
    "fig.savefig(\"plots/significance_cut_scan.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like we should use a cut of $x>45$ or so.\n",
    "Now for the autodiff version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's calculate a gradient\n",
    "With `jax` we get the gradient of `get_significance` by just calling `grad()`.\n",
    "The argument `argnums=0` means that we want the gradient wrt. the first argument, which is the cut value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_significance = grad(get_significance, argnums=0)\n",
    "\n",
    "# let's calculate the derivative for a few values\n",
    "significances_prime = [grad_significance(cut, signal, background) for cut in cuts]\n",
    "plt.plot(cuts, significances_prime, c=\"C3\")\n",
    "plt.xlabel(\"cut position c\")\n",
    "plt.ylabel(\"gradient of significance\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This did not quite work out.\n",
    "The problem here is that the significance function is actually flat almost everywhere, and the gradient is only non-zero exactly where events are located.\n",
    "The significance changes as single events leave the bin that we use for the measurement, so it changes at the positions of all the events.\n",
    "We need something else to properly do what we want.\n",
    "To confirm the above, let's have a very zoomed in look at the significance as a function of the cut position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts_zoomed = jnp.linspace(60.7, 61.0, 500)  # zoom in to see step function behavior\n",
    "significances_zoomed = [\n",
    "    get_significance(cut, signal, background) for cut in cuts_zoomed\n",
    "]\n",
    "plt.plot(cuts_zoomed, significances_zoomed, c=\"C2\")\n",
    "plt.xlabel(\"cut position c\")\n",
    "plt.ylabel(\"significance\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making it work\n",
    "Instead of working with the non-differential cut operation, let's replace it by something differentiable.\n",
    "We give weights to all our events.\n",
    "Those weights should be `1` in the limit where the events are very far above the cut, and `0` if they are very far below the cut.\n",
    "\n",
    "We can use a sigmoid $1 / [1+e^{-\\alpha(x-c)}]$ to calculate the weight, where $c$ is the cut value and $\\alpha$ a parameter that adjust the steepness.\n",
    "Larger values of $\\alpha$ make the function steeper in the transition region around the cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_after_cut(x, c, alpha=1):\n",
    "    \"\"\"calculate the number of events passing a certain cut\"\"\"\n",
    "    # If alpha is too large -> NaNs later on...\n",
    "    passed = 1 / (1 + jnp.exp(-alpha * (x - c)))\n",
    "    return passed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the weight as a function of observable for a given cut value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.linspace(30, 60, 100)\n",
    "example_cut = 45\n",
    "y_pass = yield_after_cut(x, example_cut, alpha=1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# ax.plot(x, y_pass, c=\"C4\", label=r\"$\\alpha=1$\")\n",
    "ax.plot(x, yield_after_cut(x, example_cut, alpha=0.5), label=r\"$\\alpha=0.5$\")\n",
    "ax.plot(x, y_pass, label=r\"$\\alpha=1$\", color=\"C3\")\n",
    "ax.plot(x, yield_after_cut(x, example_cut, alpha=2), label=r\"$\\alpha=2$\")\n",
    "ax.plot([example_cut, example_cut], [0, 1], \":\", c=\"k\")\n",
    "ax.set_xlabel(r\"Observable $x$\")\n",
    "ax.set_ylabel(\"Event weight\")\n",
    "ax.set_title(\"Example cut at $x=45$\")\n",
    "ax.legend(loc=\"best\")\n",
    "fig.savefig(\"plots/sigmoid_event_weights.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a new function to calculate the significance, but now instead of doing it by applying cuts we instead approximate cuts with the sigmoid approach and weights.\n",
    "We can compare this way of calculating the significance to the approach using hard cuts from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significance_smooth(cut, S, B, alpha=1):\n",
    "    \"\"\"calculate significance for a given cut, but now approximate the cut with a sigmoid\"\"\"\n",
    "    S_pass = yield_after_cut(S, cut, alpha)\n",
    "    B_pass = yield_after_cut(B, cut, alpha)\n",
    "    sum_S_weighted = jnp.sum(S_pass)\n",
    "    sum_B_weighted = jnp.sum(B_pass)\n",
    "    return significance(sum_S_weighted, sum_B_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts_smooth = jnp.linspace(20, 70, 500)\n",
    "significances_smooth_alpha_1 = jnp.asarray(\n",
    "    [get_significance_smooth(cut, signal, background, alpha=1) for cut in cuts_smooth]\n",
    ")\n",
    "significances_smooth_alpha_half = jnp.asarray(\n",
    "    [get_significance_smooth(cut, signal, background, alpha=0.5) for cut in cuts_smooth]\n",
    ")\n",
    "significances_smooth_alpha_2 = jnp.asarray(\n",
    "    [get_significance_smooth(cut, signal, background, alpha=2) for cut in cuts_smooth]\n",
    ")\n",
    "significances_smooth_alpha_3 = jnp.asarray(\n",
    "    [get_significance_smooth(cut, signal, background, alpha=3) for cut in cuts_smooth]\n",
    ")\n",
    "print(\"Optimal cut is c =\", cuts_smooth[jnp.argmax(significances_smooth_alpha_1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(cuts, significances, label=\"Hard cuts\", c=\"C2\")\n",
    "ax.plot(cuts_smooth, significances_smooth_alpha_half, label=r\"Sigmoid, $\\alpha=0.5$\")\n",
    "ax.plot(cuts_smooth, significances_smooth_alpha_1, label=r\"Sigmoid, $\\alpha=1$\", c=\"C3\")\n",
    "ax.plot(cuts_smooth, significances_smooth_alpha_2, label=r\"Sigmoid, $\\alpha=2$\")\n",
    "ax.plot(cuts_smooth, significances_smooth_alpha_3, label=r\"Sigmoid, $\\alpha=3$\")\n",
    "ax.set_xlabel(\"Cut position $c$\")\n",
    "ax.set_ylabel(\"Significance\")\n",
    "ax.legend(loc=\"best\")\n",
    "fig.savefig(\"plots/significance_scan_compare.png\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(cuts, significances, label=\"Hard cuts\", c=\"C2\")\n",
    "ax.plot(cuts_smooth, significances_smooth_alpha_3, label=r\"Sigmoid, $\\alpha=3$\")\n",
    "ax.set_xlabel(\"Cut position $c$\")\n",
    "ax.set_ylabel(\"Significance\")\n",
    "ax.legend(loc=\"best\")\n",
    "fig.savefig(\"plots/significance_scan_compare_high_alpha.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smooth version seems to be a decent approximation.\n",
    "We can in principle improve it by increasing the steepness $\\alpha$, but run into some `NaN` issues in the next step (insights welcome of how to solve this, we can already introduce them in the state above be `@jit`-ing the function).\n",
    "\n",
    "Now let's calculate the gradient of the smooth function above, and evaluate it for a few cut values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_gradient_function = grad(get_significance_smooth, argnums=0)\n",
    "sig_prime_smooth = jnp.asarray(\n",
    "    [sig_gradient_function(cut, signal, background, alpha=1) for cut in cuts_smooth]\n",
    "    #     [sig_gradient_function(cut, signal, background, alpha=2) for cut in cuts_smooth]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The big moment has come!\n",
    "Time to take a look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intercept_indices(arr):\n",
    "    \"\"\"find where an array of values intercepts zero\"\"\"\n",
    "    intercepts = []\n",
    "    for i in range(len(arr)):\n",
    "        # check if sign changed, meaning zero was crossed\n",
    "        if arr[i] * arr[i + 1] < 0:\n",
    "            # pick side closer to zero and return index\n",
    "            if jnp.abs(arr[i]) > jnp.abs(arr[i + 1]):\n",
    "                intercepts.append(i + 1)\n",
    "            else:\n",
    "                intercepts.append(i)\n",
    "    return jnp.asarray(intercepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercepts = get_intercept_indices(sig_prime_smooth)\n",
    "cut_values = jnp.asarray([cuts_smooth[intercept] for intercept in intercepts])\n",
    "\n",
    "print(f\"intercepts of the gradient with zero are located at {cut_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1)\n",
    "fig.set_size_inches(10, 10)\n",
    "# draw significance again\n",
    "axs[0].plot(cuts_smooth, significances_smooth_alpha_1, color=\"C3\", label=r\"$\\alpha$=1\")\n",
    "# plt.plot(cuts_smooth, significances_smooth_alpha_2, color=\"C3\")\n",
    "axs[0].set_xlabel(r\"Cut position $c$\")\n",
    "axs[0].set_ylabel(\"Significance\")\n",
    "axs[0].legend(loc=\"best\")\n",
    "\n",
    "# add gradient\n",
    "axs[1].plot([20, 70], [0, 0], \"--\", color=\"grey\")\n",
    "axs[1].plot(cuts_smooth, sig_prime_smooth, color=\"C3\")\n",
    "\n",
    "xmin, xmax, ymin, ymax = axs[1].axis()\n",
    "\n",
    "for cval in cut_values:\n",
    "    axs[1].plot([cval, cval], [ymin, ymax], \":\", color=\"k\")\n",
    "axs[1].set_xlabel(r\"Cut position $c$\")\n",
    "axs[1].set_ylabel(\"Gradient of significance\")\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(\"plots/significance_gradient.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the maximum significance at the point where the gradient of the significance intercepts zero (and could in principle check the second derivative to make sure this is not a saddle point)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic analysis optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a last step, let's write a simple gradient ascent function to find the point of maximum significance.\n",
    "In the example below this is computationally far less efficient than a scan, but with a better implementation and a higher dimensional problem the approach really shines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 1_000\n",
    "\n",
    "c0 = 20.0  # initial position\n",
    "step_size = 2  # step size\n",
    "\n",
    "steps_taken = []\n",
    "\n",
    "for i in range(steps):\n",
    "    # reduce step size after a while\n",
    "    if i % 500 == 0 and i != 0:\n",
    "        step_size = step_size / 5\n",
    "    grad_at_pos = sig_gradient_function(c0, signal, background)\n",
    "    if i % 250 == 0:\n",
    "        print(\"current position is\", c0, \"and the gradient is\", grad_at_pos)\n",
    "    c0 = c0 + step_size * grad_at_pos\n",
    "    if i % 50 == 0:\n",
    "        steps_taken.append(c0)\n",
    "\n",
    "print(\"final position is\", c0)\n",
    "\n",
    "# calculate the significance at a few steps along the way to visualize\n",
    "sig_at_steps = jnp.asarray(\n",
    "    [get_significance_smooth(step, signal, background, alpha=1) for step in steps_taken]\n",
    "    #         [get_significance_smooth(step, signal, background, alpha=2) for step in steps_taken]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(cuts_smooth, significances_smooth_alpha_1, c=\"C3\", label=r\"$\\alpha=1$\")\n",
    "# ax.plot(cuts_smooth, significances_smooth_alpha_2, c=\"C3\", label=r\"$\\alpha=2$\")\n",
    "ax.plot(steps_taken, sig_at_steps, \"o\", c=\"C4\", label=\"At each 50th step\")\n",
    "ax.set_xlabel(r\"Cut position $c$\")\n",
    "ax.set_ylabel(\"Significance\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "fig.savefig(\"plots/automated_optimization.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
